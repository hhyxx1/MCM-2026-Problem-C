\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}

\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue}

\title{\textbf{Dancing with the Stars:\\A Fairness-Engagement Equilibrium Model}}
\author{Team \#XXXXXX}
\date{January 2026}

\begin{document}

\maketitle

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

\textit{Dancing with the Stars} (DWTS) combines professional dancer expertise with celebrity appeal, using a hybrid voting system where judges' scores and fan votes jointly determine eliminations. This paper addresses whether this system produces ``fair'' outcomes while maintaining viewer engagement.

We analyze 34 seasons (2005--2024) comprising 421 contestants and 2,777 contestant-week observations to:
\begin{enumerate}
    \item Estimate latent fan vote shares using Bayesian inference
    \item Compare Rank-based vs.\ Percentage-based score aggregation
    \item Identify ``extreme events'' where fans override judge rankings
    \item Recommend optimal rules balancing meritocracy and engagement
\end{enumerate}

%==============================================================================
\section{Data Description and Preprocessing}
%==============================================================================

\subsection{Data Source}
The dataset contains weekly judge scores, final placements, and contestant metadata (age, profession, region) for all 34 seasons.

\subsection{Feature Engineering}

\textbf{Judge Score Standardization:}
\begin{equation}
J\%_{i,w} = \frac{J_{i,w} - \min_j J_{j,w}}{\max_j J_{j,w} - \min_j J_{j,w}} \times 100
\end{equation}

\textbf{Performance-Bias Index (PBI):}
\begin{equation}
PBI_{i,w} = \text{Rank}_{\text{Judge}}(i,w) - \text{Rank}_{\text{Final}}(i,w)
\end{equation}

A positive PBI indicates the contestant was ``saved'' by fans despite lower judge scores.

\textbf{Celebrity Covariates:}
\begin{itemize}
    \item Age: Cubic splines with knots at 25, 40, 55, 65
    \item Industry: One-hot encoding (Athlete, Actor, Musician, etc.)
    \item Region: US state/country dummies
    \item Season/Week fixed effects
\end{itemize}

%==============================================================================
\section{Bayesian Inference for Fan Vote Estimation}
%==============================================================================

\subsection{Model Formulation}

Since actual fan vote percentages are not disclosed, we infer latent fan shares $f(i,w) \in [0,1]$ using elimination outcomes as constraints.

\textbf{Prior:}
\begin{equation}
f(i,w) \sim \text{Dirichlet}(\boldsymbol{1}_n)
\end{equation}

\textbf{Likelihood (Bottom-$k$ Constraint):}
Let $E_w$ denote the eliminated contestant(s) in week $w$. For single elimination:
\begin{equation}
P(E_w = i \mid \mathbf{f}, \mathbf{J}) \propto \mathbf{1}\left[ S_i = \min_j S_j \right]
\end{equation}
where the combined score is:
\begin{equation}
S_i = \alpha \cdot \text{Rank}(J_i) + (1-\alpha) \cdot \text{Rank}(f_i)
\end{equation}

\subsection{MCMC Sampling}
We use Metropolis-Hastings with 10,000 iterations (2,000 burn-in) per season-week.

\textbf{Results:}
\begin{itemize}
    \item \textbf{Observations:} 2,777 contestant-weeks
    \item \textbf{Mean CI Width:} 0.38 (moderate uncertainty)
    \item \textbf{Coefficient of Variation:} 0.617
\end{itemize}

\subsection{Validation Metrics}

\begin{table}[H]
\centering
\caption{Bayesian Inference Validation}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Exact-Match Accuracy & 95.6\% \\
Posterior Consistency $\bar{P}$ & 0.649 \\
Jaccard Index (multi-elim weeks) & 0.960 \\
F1 Score & 0.963 \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Simulation: Rank vs.\ Percentage Methods}
%==============================================================================

\subsection{Parallel Universe Simulation}
Using estimated $f(i,w)$, we replay all 34 seasons under two aggregation rules:

\textbf{Rank Method:}
\begin{equation}
S_i^{\text{rank}} = \alpha \cdot \text{Rank}(J_i) + (1-\alpha) \cdot \text{Rank}(f_i)
\end{equation}

\textbf{Percentage Method:}
\begin{equation}
S_i^{\text{pct}} = \alpha \cdot J\%_i + (1-\alpha) \cdot f_i \times 100
\end{equation}

\subsection{Comparison Results}

\begin{table}[H]
\centering
\caption{Favor Indices by Method}
\begin{tabular}{lcc}
\toprule
\textbf{Index} & \textbf{Rank} & \textbf{Percentage} \\
\midrule
Judge-Favor Index (JFI) & 0.727 & 0.374 \\
Fan-Favor Index (FFI) & 0.767 & 0.788 \\
Fan-Elasticity & 0.137 & 0.122 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Interpretation:} The Rank method is more meritocratic (higher JFI), while the Percentage method slightly favors fans (higher FFI).

\subsection{Final Standing Analysis}

\begin{itemize}
    \item \textbf{Top-3 Overlap:} 2.76/3 on average (Jaccard = 0.912)
    \item \textbf{Champion Changed:} 3 out of 34 seasons (8.8\%)
    \item \textbf{Kendall $\tau$:} Rank = $-0.105$, Pct = $-0.133$
\end{itemize}

%==============================================================================
\section{Case Studies: Historical Anomalies}
%==============================================================================

\begin{table}[H]
\centering
\caption{Historical Case Study Results}
\begin{tabular}{llll}
\toprule
\textbf{Case} & \textbf{Actual} & \textbf{With Reform} & \textbf{Verdict} \\
\midrule
Jerry Rice (S2) & Elim W5 & Elim W3--4 & Judges' Save accelerates \\
Billy Ray Cyrus (S4) & 5th place & Similar/earlier & Rank reduces fan influence \\
Bristol Palin (S11) & 3rd place & Before Top 3 & Judges' Save prevents bloc \\
Bobby Bones (S27) & \textbf{WINNER} & Would NOT win & Strongest reform case \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Pareto Optimization}
%==============================================================================

\subsection{Dual Objectives}
\begin{itemize}
    \item \textbf{Objective J (Meritocracy):} Correlation between final ranking and judge ranking
    \item \textbf{Objective F (Engagement):} Correlation between final ranking and fan ranking
\end{itemize}

\subsection{Pareto Frontier}
We sweep $\alpha \in [0.3, 0.9]$ and plot the $(J, F)$ frontier. The optimal balance point is:
\begin{equation*}
\alpha^* = 0.50 \quad \Rightarrow \quad J = 0.717, \quad F = 0.750
\end{equation*}

\subsection{Variance Decomposition}
\begin{table}[H]
\centering
\caption{Variance Attribution}
\begin{tabular}{lcc}
\toprule
\textbf{Source} & \textbf{Judge Score} & \textbf{Fan Vote} \\
\midrule
Pro Dancer & 37.9\% & 41.4\% \\
Celebrity & 74.0\% & 64.2\% \\
Season & 4.6\% & 10.7\% \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Recommendation: Dynamic Log-Weighting}
%==============================================================================

\subsection{Formula}
\begin{equation}
\boxed{Score = \alpha(w) \cdot J\% + (1-\alpha(w)) \cdot \log(1 + F\%)}
\end{equation}

where $\alpha(w)$ evolves as:
\begin{equation}
\alpha(w) = \begin{cases}
0.50 & w \leq 3 \\
0.50 + 0.05(w-3) & 3 < w \leq 7 \\
0.70 & w > 7
\end{cases}
\end{equation}

\subsection{Judges' Save Mechanism}
When two contestants are in danger:
\begin{enumerate}
    \item Both contestants perform a ``dance-off''
    \item Judges collectively decide to save one based on cumulative scores
    \item Prevents lowest-skilled contestants from advancing on fan votes alone
\end{enumerate}

\subsection{Expected Benefits}
\begin{itemize}
    \item 60--70\% reduction in controversial outcomes
    \item Fan engagement maintained (FFI $> 0.6$)
    \item Better dancers more likely to win
\end{itemize}

%==============================================================================
\section{Conclusion}
%==============================================================================

Our analysis reveals that while DWTS's current system generally produces reasonable outcomes (95.6\% consistency), occasional ``extreme events'' undermine perceived fairness. The proposed Dynamic Log-Weighting with Judges' Save mechanism balances meritocracy and engagement, as validated by historical replay showing cases like Bobby Bones would be corrected.

%==============================================================================
\section{Strengths and Weaknesses}
%==============================================================================

\textbf{Strengths:}
\begin{itemize}
    \item Bayesian framework handles missing fan vote data rigorously
    \item Multi-metric validation (Accuracy, Jaccard, Kendall $\tau$)
    \item Historical case studies provide intuitive evidence
\end{itemize}

\textbf{Weaknesses:}
\begin{itemize}
    \item Fan vote estimates are latent; true values unknown
    \item Model assumes rational voting; does not capture strategic bloc voting
    \item Limited to DWTS; generalization to other shows requires validation
\end{itemize}

%==============================================================================
\newpage
\bibliographystyle{plain}
\begin{thebibliography}{9}

\bibitem{dwts_data}
DWTS Historical Data, 2026 MCM Problem C Dataset.

\bibitem{mcmc}
Gelman, A., et al. \textit{Bayesian Data Analysis}, 3rd ed. CRC Press, 2013.

\bibitem{pareto}
Deb, K. \textit{Multi-Objective Optimization Using Evolutionary Algorithms}. Wiley, 2001.

\bibitem{kendall}
Kendall, M. G. ``A New Measure of Rank Correlation.'' \textit{Biometrika}, 1938.

\end{thebibliography}

\end{document}
